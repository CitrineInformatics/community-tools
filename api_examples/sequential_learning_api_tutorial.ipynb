{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCC Sequential Learning Tutorial\n",
    "\n",
    "*Authors: Edward Kim, Enze Chen*\n",
    "\n",
    "In this notebook, we will cover how to perform **sequential learning** (SL) using the [Citrination API](http://citrineinformatics.github.io/python-citrination-client/). Sequential learning is the key workflow which allows machine learning algorithms and in-lab experiments to iteratively inform each other.\n",
    "\n",
    "To replace the need for an actual laboratory, this notebook uses a simple *toy function* that allows for \"measurements\" on the data.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of this tutorial, you will know how to:\n",
    "\n",
    "- Use PyCC end to end, from uploading an initial dataset to running SL\n",
    "- Understand how to configure SL parameters to match your laboratory setup\n",
    "- Asynchronously issue SL jobs to Citrination's backend\n",
    "\n",
    "## Background knowledge\n",
    "\n",
    "In order to get the most out of this tutorial, you should already be familiar with the following:\n",
    "\n",
    "- Create and access datasets through the API ([documentation](http://citrineinformatics.github.io/python-citrination-client/tutorial/data_examples.html) and [tutorial](https://github.com/CitrineInformatics/community-tools/blob/master/api_examples/data_client_api_tutorial.ipynb))\n",
    "- Create and access data views through the API ([tutorial](https://github.com/CitrineInformatics/community-tools/blob/master/api_examples/data_views_api_tutorial.ipynb))\n",
    "- What the data views [front-end UI](https://citrination.com/data_views) looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEFORE YOU RUN THIS NOTEBOOK\n",
    "\n",
    "This notebook uses some convenience functions to wrap several API endpoints. These are listed at the end of the notebook in the section titled **Convenience functions**. Run those functions first before running the main notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard packages\n",
    "from os import environ\n",
    "from time import sleep\n",
    "\n",
    "# Third-party packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pypif import pif\n",
    "from pypif.obj import *\n",
    "from citrination_client import CitrinationClient\n",
    "from citrination_client.models.design import Target\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a client\n",
    "\n",
    "Make sure to properly set your **environment variable** to hold your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CitrinationClient(\n",
    "    environ.get(\"CITRINATION_API_KEY_PUBLIC\"),\n",
    "    \"https://citrination.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "Since we aren't using a real laboratory, we need access to a quick way to generate \"correct\" measurements. A simple placeholder here is to use a function that sums the squares of its inputs. The goal, in this case, will be to find the global minimum. \n",
    "\n",
    "In a real example, we could minimize or maximize any output: compressive strengths, conductivities, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_func(inputs):\n",
    "    func_sum = 0.0\n",
    "    for inp in inputs:\n",
    "        func_sum += inp**2\n",
    "    return func_sum\n",
    "\n",
    "toy_x = [np.random.normal(loc=3.0, scale=1.0, size=(1, 2))[0] for x in range(10)]\n",
    "toy_y = [toy_func(x) for x in toy_x]\n",
    "\n",
    "initial_best_measured_value = min(toy_y)\n",
    "\n",
    "print(f\"Best (lowest) value in initial training set: {initial_best_measured_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the initial training set, and color it by the function value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot initial training set, colored by toy function values\n",
    "\n",
    "plt.scatter(np.array(toy_x)[:,0], np.array(toy_x)[:,1],\n",
    "            c=toy_y, cmap=plt.cm.plasma)\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.xlim(-5,5)\n",
    "plt.ylim(-5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write a PIF JSON dataset file\n",
    "write_dataset_from_func(toy_func, \"toy_initial_dataset.json\", toy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataset, upload to Citrination, return/print the ID\n",
    "\n",
    "dataset_id = upload_data_and_get_id(\n",
    "    client,\n",
    "    \"toy_initial_dataset\",\n",
    "    \"toy_initial_dataset.json\",\n",
    "    create_new_version=True,\n",
    "#   given_dataset_id=1234\n",
    ")\n",
    "print(f\"Dataset created: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a data view on Citrination, return/print the ID\n",
    "# view_id = 1234 # If view exists and you're re-running this notebook\n",
    "\n",
    "view_id = build_view_and_get_id(client, dataset_id, \"toy_view\", view_desc=\"toy test view\",\n",
    "                      input_keys=[\"Property x1\", \"Property x2\"], output_keys=[\"Property y\"])\n",
    "\n",
    "print(f\"Data view created: {view_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running design\n",
    "\n",
    "Now we call a function that runs the SL process. In short, we run a loop where we do the following:\n",
    "\n",
    "1. Submit a design run (and poll status w/ wait times)\n",
    "1. Get best candidates and record predicted results\n",
    "1. Measure candidates (using toy function evaluation) and record measured results\n",
    "1. Add candidates to dataset\n",
    "1. Retrain on dataset (and poll status w/ wait times)\n",
    "1. Repeat until max iterations reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sl_results = {}\n",
    "\n",
    "best_sl_pred_vals, best_sl_measured_vals = run_design(\n",
    "    client=client,\n",
    "    view_id=str(view_id),\n",
    "    dataset_id=str(dataset_id),\n",
    "    num_candidates_per_iter=20,\n",
    "    design_effort=25,\n",
    "    wait_time=2,\n",
    "    num_sl_iterations=5,\n",
    "    input_properties=[\"Property x1\", \"Property x2\"],\n",
    "    target=[\"Property y\", \"Min\"],\n",
    "    print_output=True,\n",
    "    true_function=toy_func,\n",
    "    score_type=\"MLI\"\n",
    ")\n",
    "\n",
    "# Reset dataset after each SL run\n",
    "dataset_id = upload_data_and_get_id(\n",
    "    client,\n",
    "    \"toy_initial_dataset\",\n",
    "    \"toy_initial_dataset.json\",\n",
    "    create_new_version=True,\n",
    "    given_dataset_id=dataset_id\n",
    ")\n",
    "\n",
    "sl_results[\"predicted\"] = best_sl_pred_vals\n",
    "sl_results[\"measured\"] = best_sl_measured_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the results\n",
    "\n",
    "Finally, we can plot the results: Here, we are plotting the best measured candidate against the number of SL iterations. In this case, lower = better for the measured results (since we are doing function minimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    x=np.arange(1, len(sl_results[\"measured\"])+1),\n",
    "    y=[round(float(v), 3) for v in sl_results[\"measured\"]],\n",
    "    estimator=None,\n",
    "    markers=True,\n",
    "    label=f\"Measured Results\",\n",
    "    legend=False,\n",
    "\n",
    ")\n",
    "plt.xlabel(\"SL Iteration #\")\n",
    "plt.legend(loc='best', bbox_to_anchor=(1.9, 1.0))\n",
    "plt.ylabel(\"Function Value\")\n",
    "plt.title(f\"Optimizing using {score_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "To recap, this notebook went through the steps for running SL using the API.\n",
    "1. First, we created and uploaded an initial dataset.\n",
    "1. Then, we created a data view and trained the model.\n",
    "1. We ran the SL process, measuring and updating new candidates after each iteration.\n",
    "1. Finally we examined our SL results.\n",
    "\n",
    "## Additional resources\n",
    "It's now possible to conduct the major aspects of the Citrination workflow through the API, which should increase the speed and flexibility of informatics approaches. Some other topics that might interest you include:\n",
    "* More details regarding client functions in the [code base](https://github.com/CitrineInformatics/python-citrination-client/blob/develop/citrination_client/views/client.py).\n",
    "* [DataClient](http://citrineinformatics.github.io/python-citrination-client/tutorial/data_examples.html) - This allows you to create datasets and upload PIF data (only) using the API.\n",
    "  * There is also a corresponding [tutorial](https://github.com/CitrineInformatics/community-tools/blob/master/api_examples/data_client_api_tutorial.ipynb).\n",
    "* [SearchClient](http://citrineinformatics.github.io/python-citrination-client/tutorial/search_examples.html) - This gives you a flexible and fast way to access PIF data on Citrination.\n",
    "  * In particular, take a look at our [Intro](https://github.com/CitrineInformatics/learn-citrination/blob/master/IntroQueries.ipynb) and [Advanced](https://github.com/CitrineInformatics/learn-citrination/blob/master/AdvancedQueries.ipynb) tutorials for how to construct queries.\n",
    "* Other examples on [learn-citrination](https://github.com/CitrineInformatics/learn-citrination)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions (Run these first!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra imports for convenience functions\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from time import sleep\n",
    "from typing import Callable, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "from citrination_client import (CitrinationClient, DataQuery, DatasetQuery,\n",
    "                                Filter, PifSystemReturningQuery,\n",
    "                                RealDescriptor)\n",
    "from citrination_client.models.design import Target\n",
    "from citrination_client.views.data_view_builder import DataViewBuilder\n",
    "from pypif import pif\n",
    "from pypif.obj import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_from_func(test_function:Callable[[np.ndarray], float],\n",
    "                        filename:str, input_vals:List[np.ndarray]) -> None:\n",
    "    '''Given a function, write a dataset evaluated on given input values\n",
    "    \n",
    "    :param test_function: Function for generating dataset\n",
    "    :type test_function: Callable[[np.ndarray], float]\n",
    "    :param filename: Name of file for saving CSV dataset\n",
    "    :type filename: str\n",
    "    :param input_vals: List of input values to eval function over\n",
    "    :type input_vals: np.ndarray\n",
    "    :return: Doesn't return anything\n",
    "    :rtype: None\n",
    "    '''\n",
    "\n",
    "    pif_systems = []    \n",
    "    for i, val_row in enumerate(input_vals):\n",
    "        system = System()\n",
    "        system.names = f'{test_function.__name__}_{i}' \n",
    "        system.properties =  []\n",
    "\n",
    "        for j, x_val in enumerate(val_row):\n",
    "            func_input = Property()\n",
    "            func_input.name = f\"x{j+1}\"\n",
    "            func_input.scalars = x_val\n",
    "            system.properties.append(func_input)\n",
    "\n",
    "        func_output = Property()\n",
    "        func_output.name = f\"y\"\n",
    "        func_output.scalars = test_function(val_row)\n",
    "        system.properties.append(func_output)\n",
    "        pif_systems.append(system)\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(pif.dumps(pif_systems, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data_and_get_id(client:CitrinationClient,\n",
    "                        dataset_name:str,\n",
    "                        dataset_local_fpath:str,\n",
    "                        create_new_version:Optional[bool] = False,\n",
    "                        given_dataset_id:Optional[int] = None) -> int:\n",
    "    '''Uploads data to a new/given dataset and returns its ID\n",
    "    \n",
    "    :param client: Client API object to pass in\n",
    "    :type client: CitrinationClient\n",
    "    :param dataset_name: Name of dataset\n",
    "    :type dataset_name: str\n",
    "    :param dataset_local_fpath: Local data filepath\n",
    "    :type dataset_local_fpath: str\n",
    "    :param create_new_version: Whether or not to make a new version\n",
    "    :param create_new_version: bool\n",
    "    :param given_dataset_id: ID if using existing dataset, defaults to None\n",
    "    :param given_dataset_id: int\n",
    "    :return: ID of the dataset\n",
    "    :rtype: int\n",
    "    '''\n",
    "\n",
    "\n",
    "    if given_dataset_id is None:\n",
    "        dataset = client.data.create_dataset(dataset_name)\n",
    "        dataset_id = dataset.id\n",
    "    else:   \n",
    "        dataset_id = given_dataset_id\n",
    "        if create_new_version:\n",
    "            client.data.create_dataset_version(dataset_id)\n",
    "\n",
    "    client.data.upload(dataset_id, dataset_local_fpath)\n",
    "    assert (client.data.matched_file_count(dataset_id) >= 1), \"Upload failed.\"\n",
    "    return dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_view_and_get_id(client:CitrinationClient, dataset_id:int,\n",
    "                        view_name:str, input_keys:List[str], \n",
    "                        output_keys:List[str], view_desc:str = \"\",\n",
    "                        wait_time:int = 2, print_output:bool = False) -> int:\n",
    "    '''Builds a new data view and returns the view ID\n",
    "    \n",
    "    :param client: Client object\n",
    "    :type client: CitrinationClient\n",
    "    :param dataset_id: Dataset to build view from\n",
    "    :type dataset_id: int\n",
    "    :param view_name: Name of the new view\n",
    "    :type view_name: str\n",
    "    :param input_keys: Input key names\n",
    "    :type input_keys: List[str]\n",
    "    :param output_keys: Output key names\n",
    "    :type output_keys: List[str]\n",
    "    :param view_desc: Description for the view, defaults to \"\"\n",
    "    :param view_desc: str, optional\n",
    "    :param wait_time: Wait time in seconds before polling API\n",
    "    :type wait_time: int\n",
    "    :param print_output: Whether or not to print outputs\n",
    "    :type print_output: bool\n",
    "    :return: ID of the view\n",
    "    :rtype: int\n",
    "    '''\n",
    "\n",
    "    dv_builder = DataViewBuilder()\n",
    "    dv_builder.dataset_ids([str(dataset_id)])\n",
    "    dv_builder.model_type('default') # random forest\n",
    "\n",
    "    for key_name in input_keys:\n",
    "        desc_x = RealDescriptor(key=key_name)\n",
    "        dv_builder.add_descriptor(desc_x, role='input')\n",
    "\n",
    "    for key_name in output_keys:\n",
    "        desc_y = RealDescriptor(key=key_name)\n",
    "        dv_builder.add_descriptor(desc_y, role='output')\n",
    "\n",
    "    dv_config = dv_builder.build()\n",
    "\n",
    "    _wait_on_ingest(client, dataset_id, wait_time, print_output)\n",
    "\n",
    "    dv_id = client.data_views.create(\n",
    "        dv_config, \n",
    "        name=view_name, \n",
    "        description=view_desc\n",
    "    )\n",
    "    return dv_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_design(client:CitrinationClient, view_id:int, dataset_id:int,\n",
    "                        num_candidates_per_iter:int,\n",
    "                        design_effort:int, wait_time:int, \n",
    "                        num_sl_iterations:int, input_properties:List[str],\n",
    "                        target:List[str], print_output:bool,\n",
    "                        true_function:Callable[[np.ndarray], float],\n",
    "                        score_type:str,\n",
    "                        ) -> Tuple[List[float], List[float]]:\n",
    "    '''Runs SL design\n",
    "    \n",
    "    :param client: Client object\n",
    "    :type client: CitrinationClient\n",
    "    :param view_id: View ID\n",
    "    :type view_id: int\n",
    "    :param dataset_id: Dataset ID\n",
    "    :type dataset_id: int\n",
    "    :param num_candidates_per_iter: Candidates in a batch\n",
    "    :type num_candidates_per_iter: int\n",
    "    :param design_effort: Effort from 1-30\n",
    "    :type design_effort: int\n",
    "    :param wait_time: Wait time in seconds before polling API\n",
    "    :type wait_time: int\n",
    "    :param num_sl_iterations: SL iterations to run\n",
    "    :type num_sl_iterations: int\n",
    "    :param input_properties: Inputs\n",
    "    :type input_properties: List[str]\n",
    "    :param target: (\"Output property\", {\"Min\", \"Max\"})\n",
    "    :type target: List[str]\n",
    "    :param print_output: Whether or not to print outputs\n",
    "    :type print_output: bool\n",
    "    :param true_function: Actual function for evaluating measured/true values\n",
    "    :type true_function: Callable[[np.ndarray], float]\n",
    "    :param score_type: MLI or MEI\n",
    "    :type score_type: str\n",
    "    :return: 2-tuple: list of predicted scores/uncertainties; list of measured scores/uncertainties\n",
    "    :rtype: Tuple[List[float], List[float]]\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    best_sl_pred_vals = []\n",
    "    best_sl_measured_vals = []\n",
    "\n",
    "    _wait_on_ingest(client, dataset_id, wait_time, print_output)\n",
    "\n",
    "    for i in range(num_sl_iterations):\n",
    "        if print_output:\n",
    "            print(f\"\\n---STARTING SL ITERATION #{i+1}---\")\n",
    "\n",
    "        _wait_on_ingest(client, dataset_id, wait_time, print_output)\n",
    "        _wait_on_data_view(client, dataset_id, view_id, wait_time, print_output)\n",
    "            \n",
    "        # Submit a design run\n",
    "        design_id = client.submit_design_run(\n",
    "                data_view_id=view_id,\n",
    "                num_candidates=num_candidates_per_iter, \n",
    "                effort=design_effort, \n",
    "                target=Target(*target), \n",
    "                constraints=[], \n",
    "                sampler=\"Default\"\n",
    "            ).uuid\n",
    "        \n",
    "        if print_output:\n",
    "            print(f\"Created design run with ID {design_id}\")\n",
    "\n",
    "        _wait_on_design_run(client, design_id, view_id, wait_time, print_output)\n",
    "\n",
    "        # Compute the best values with uncertainties as a list of (value, uncertainty)\n",
    "        if score_type == \"MEI\":\n",
    "            candidates = client.get_design_run_results(view_id, design_id).best_materials\n",
    "        else:\n",
    "            candidates = client.get_design_run_results(view_id, design_id).next_experiments\n",
    "        values_w_uncertainties = [\n",
    "            (\n",
    "                m[\"descriptor_values\"][target[0]], \n",
    "                m[\"descriptor_values\"][f\"Uncertainty in {target[0]}\"]\n",
    "            ) for m in candidates\n",
    "        ]\n",
    "\n",
    "        # Find and save the best predicted value\n",
    "        if target[1] == \"Min\":\n",
    "            best_value_w_uncertainty = min(values_w_uncertainties, key=lambda x: x[0])\n",
    "        else:\n",
    "            best_value_w_uncertainty = max(values_w_uncertainties, key=lambda x: x[0])\n",
    "\n",
    "        best_sl_pred_vals.append(best_value_w_uncertainty)\n",
    "        if print_output: \n",
    "            print(f\"SL iter #{i+1}, best predicted (value, uncertainty) = {best_value_w_uncertainty}\")\n",
    "            \n",
    "        # Update dataset w/ new candidates\n",
    "        new_x_vals = []\n",
    "        for material in candidates:\n",
    "            new_x_vals.append(np.array(\n",
    "                [float(material[\"descriptor_values\"][x]) for x in input_properties]\n",
    "            ))\n",
    "        \n",
    "        temp_dataset_fpath = f\"design-{design_id}.json\"\n",
    "        write_dataset_from_func(true_function, temp_dataset_fpath, new_x_vals)\n",
    "        upload_data_and_get_id(\n",
    "            client,\n",
    "            \"\", # No name needed for updating a dataset\n",
    "            temp_dataset_fpath,\n",
    "            given_dataset_id=dataset_id\n",
    "        )\n",
    "\n",
    "        _wait_on_ingest(client, dataset_id, wait_time, print_output)\n",
    "        \n",
    "        if print_output:\n",
    "            print(f\"Dataset updated: {len(new_x_vals)} candidates added\")\n",
    "            \n",
    "        query_dataset = PifSystemReturningQuery(size=9999, \n",
    "                            query=DataQuery(\n",
    "                            dataset=DatasetQuery(\n",
    "                                id=Filter(equal=str(dataset_id))\n",
    "                        )))\n",
    "        query_result = client.search.pif_search(query_dataset)      \n",
    "\n",
    "        if print_output:\n",
    "            print(f\"New dataset contains {query_result.total_num_hits} PIFs\")\n",
    "        \n",
    "        # Update measured values in new dataset\n",
    "        dataset_y_values = []\n",
    "        for hit in query_result.hits:\n",
    "            # Assume last prop is output if following this script\n",
    "            dataset_y_values.append(\n",
    "                float(hit.system.properties[-1].scalars[0].value)\n",
    "            )\n",
    "        \n",
    "        if target[1] == \"Min\":\n",
    "            best_sl_measured_vals.append(min(dataset_y_values))\n",
    "        else:\n",
    "            best_sl_measured_vals.append(max(dataset_y_values))\n",
    "                            \n",
    "        # Retrain model w/ wait times\n",
    "        client.data_views.retrain(view_id)\n",
    "        _wait_on_data_view(client, dataset_id, view_id, wait_time, print_output)\n",
    "    \n",
    "    if print_output:\n",
    "        print(\"SL finished!\\n\")\n",
    "    \n",
    "    return (best_sl_pred_vals, best_sl_measured_vals)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _wait_on_ingest(client:CitrinationClient, dataset_id:int, \n",
    "                        wait_time:int, print_output:bool=True) -> None:\n",
    "    # Wait for ingest to finish\n",
    "    sleep(wait_time)\n",
    "    while (client.data.get_ingest_status(dataset_id) != \"Finished\"):\n",
    "        if print_output:\n",
    "            print(\"Waiting for data ingest to complete...\")\n",
    "        sleep(wait_time)\n",
    "\n",
    "def _wait_on_data_view(client:CitrinationClient, dataset_id:int, \n",
    "                        view_id:int, wait_time:int, \n",
    "                        print_output:bool=True) -> None:\n",
    "    is_view_ready = False\n",
    "    sleep(wait_time)\n",
    "    while (not is_view_ready):\n",
    "        sleep(wait_time)\n",
    "        design_status = client.data_views.get_data_view_service_status(view_id)\n",
    "        if (design_status.experimental_design.ready and \n",
    "        design_status.predict.event.normalized_progress == 1.0):\n",
    "            is_view_ready = True\n",
    "            if print_output:\n",
    "                print(\"Design ready\")\n",
    "        else:\n",
    "            print(\"Waiting for design services...\")\n",
    "\n",
    "def _wait_on_design_run(client:CitrinationClient, design_id:int, view_id:int,\n",
    "                        wait_time:int, print_output:bool=True) -> None:\n",
    "    design_processing = True\n",
    "    sleep(wait_time)\n",
    "    while design_processing:\n",
    "        status = client.get_design_run_status(view_id, design_id).status\n",
    "        if print_output: \n",
    "            print(f\"Design run status: {status}\")\n",
    "            \n",
    "        if status != \"Finished\":\n",
    "            sleep(wait_time)\n",
    "        else:\n",
    "            design_processing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
